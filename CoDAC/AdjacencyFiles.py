import os
import requests
import numpy as np
import pandas as pd
import logging
import ast
import json
import urllib.request

def ProcessArpeggio(input_file, PATH):
        ''' This function generates a contactmap text file.
        
        Parameters
        ----------
            input_json : input a .json file generated by running Arpeggio
            PATH : PATH to find the .json input file
            OUTPATH : PAth to save the output .txt contactmap file
                    
        Returns
        -------
            Contactmap {PDB_ID}.txt to specified OUTPATH'''

       # filepath = self.PATH + '/' + self.input_json
        with open(input_file,'r') as file:
            data = json.load(file)

        contact_types=['aromatic','carbonyl','hbond','hydrophobic','ionic','polar',
                       'vdw','vdw_clash','weak_hbond','weak_polar','xbond']
        PDB_ID, ext = input_file.split('.')
        outfile = PATH+'/'+PDB_ID+'.txt'



        with open(outfile,'w') as f:
            f.write('PDB'+'\t'+'Chain1'+'\t'+'Chain2'+'\t'+'Res1'+'\t'+'ResNum1'+'\t'+
                   'Res2'+'\t'+'ResNum2'+'\t'+'Atoms'+'\t'+'Distance'+'\t'+'Contact_type'+'\n')

            for i in range(len(data)):
                chain_1 = ((data[i]['bgn']['auth_asym_id']))
                atom_1 =((data[i]['bgn']['auth_atom_id']))
                resnum_1 = (int(data[i]['bgn']['auth_seq_id']))
                res_1 = ((data[i]['bgn']['label_comp_id']))
                chain_2 = ((data[i]['end']['auth_asym_id']))
                atom_2 = ((data[i]['end']['auth_atom_id']))
                resnum_2 = (int(data[i]['end']['auth_seq_id']))
                res_2 = ((data[i]['end']['label_comp_id']))
                distance = float((data[i]['distance']))
                interaction = (data[i]['interacting_entities'])
                contactlist = data[i]['contact'] #stores data in a list 

                if interaction == 'INTRA_SELECTION':

                        if distance < 5:

                            for contact in contactlist:
                                if contact in contact_types:

                                    if resnum_1 > resnum_2:
                                        atom_pair = atom_1 +'-'+atom_2

                                        f.write(str(PDB_ID)+'\t'+str(chain_1)+'\t'+str(chain_2)+'\t'+
                                                str(res_1)+'\t'+str(resnum_1)+'\t'+str(res_2)+'\t'+str(resnum_2)+'\t'+
                                               str(atom_pair)+'\t'+str(distance)+'\t'+str(contactlist)+'\n')

                                    else:
                                        atom_pair = atom_2 +'-'+atom_1
                                        f.write(str(PDB_ID)+'\t'+str(chain_2)+'\t'+str(chain_1)+'\t'+
                                                str(res_2)+'\t'+str(resnum_2)+'\t'+str(res_1)+'\t'+str(resnum_1)+'\t'+
                                               str(atom_pair)+'\t'+str(distance)+'\t'+str(contactlist)+'\n')

                                    break

        df = pd.read_csv(outfile,  sep='\t')

        AA_dict = {"ALA":'A',
                  "ARG":'R',
                  "ASN":'N',
                  "ASP":'D',
                  "CYS":'C',
                  "GLU":'E',
                  "GLN":'Q',
                  "GLY":'G',
                  "HIS":'H',
                  "ILE":'I',
                  "LEU":'L',
                  "LYS":'K',
                  "MET":'M',
                  "PHE":'F',
                  "PRO":'P',
                  "SER":'S',
                  "THR":'T',
                  "TRP":'W',
                  "TYR":'Y',
                  "VAL":'V'}

        df.replace({"Res1": AA_dict},inplace=True)
        df.replace({"Res2": AA_dict},inplace=True)

        df.sort_values(["Chain1","Chain2","ResNum1","ResNum2"],
                            axis=0,
                            ascending=[True, True, True, True],
                            inplace=True)

        df.to_csv(outfile,sep='\t',encoding='utf-8',index=False)
        print('CM generated for {PDB}'.format(PDB= PDB_ID))

def Intraprotein_BinFea(PDB_ID,PATH):
    ''' Generates adjacency files with binary features calculated for intrachain contacts
    
    Parameters
    ----------
        PDB_ID
        PATH : to find the .txt adjacency file and also to output the file generated from this function
        
    Returns
    -------
        OUTFILE : an adjacency file with binary features and chains contributing to intraprotein contacts '''
    
    INPUTFILE = PATH+'/'+PDB_ID+'.txt'
    OUTFILE = PATH+'/'+PDB_ID+'_intra.txt'

    df = pd.read_csv(INPUTFILE, sep='\t')

    df['ResNum1_upd'] = df.loc[:, 'ResNum1']
    df['ResNum2_upd'] = df.loc[:, 'ResNum2']
    #update residue numbers if needed
    if DBREF(PDB_ID)[1].values():
        dict_resnums = (DBREF(PDB_ID)[1])
        for chain in dict_resnums.keys():
            for i in range(len(df)):
                if chain == df['Chain1'][i]:
                    df.replace({'ResNum1_upd': dict_resnums[chain]}, inplace=True) 
                    df.replace({'ResNum2_upd': dict_resnums[chain]}, inplace=True)

    #pair the chain and residue number for each row (representing a feature)
    df['ResNum pair'] = df['ResNum1_upd'].astype(str)+'-'+(df['ResNum2_upd']).astype(str)
    df['Chain Pair'] = df['Chain1'].astype(str)+'-'+(df['Chain2']).astype(str)
    
    entity_dict = entity_for_chain('1D1Z')[0]
    chain_count = len(set(entity_for_chain('1D1Z')[1]))
    unique_entities = set(entity_dict.values())
    
    for entity in unique_entities:
        threshold = intraprotein_threshold(entity_dict, entity)
        #map entity values based on chain and add columns 
        df['Entity1'] = df['Chain1'].map(entity_dict)
        df['Entity2'] = df['Chain2'].map(entity_dict)

        #for intraprotein we filter features within same chain and repeat this for all entities present
        df2 = df[df['Chain1']==df['Chain2']]
        df3 = df2[df2['Entity1']==entity]
        df3 = df3.reset_index(drop=True)
        df3.insert(11,'Binary Feature','')

        for i in range(len(df3)):
            respair = df3['ResNum pair'][i]
            #group chain pairs based on the respair to find the occurrence of the feature across all chains
            fea_in_chains = df3.loc[df3['ResNum pair'] == respair, 'Chain Pair'].values.tolist()

            #modify threshold
            if chain_count == 2: #for two chains separate condition
                if len(set(fea_in_chains)) > threshold:
                    BF = 1
                else:
                    BF = 0
            else:
                
                if len(set(fea_in_chains)) >= threshold:
                    BF = 1
                else:
                    BF = 0

            df3.at[i,'Binary Feature'] = BF

    df_edit = df3.drop(['ResNum1_upd', 'ResNum2_upd', 'ResNum pair', 'Chain Pair', 'Entity1', 'Entity2'], axis=1)
    
    df_edit.to_csv(OUTFILE, index=None, sep='\t', mode='w')
                                                                                                       

def DBREF(PDB_ID):
    ''' This function uses the DBREF record from PDB header to find differences in residue numbers between PDB and other database such as Uniprot
    
    Parameters
    ----------
        PDB_ID 
        
    Returns
    -------
        dbref_dict : dictionary with sequence start and end residue numbers for both databases along with chain
        final_dict : if differences found, the PDB sequence numbers will be replaced by the Uniprot residue number values stored in this dict '''
        
    dbref_dict={}
    
    response = urllib.request.urlopen("https://files.rcsb.org/header/"+ \
                        PDB_ID + ".pdb")
    for line in response:
        list_attributes = []
        line = (line.strip())
        if (line.startswith(b'DBREF')):
            if isinstance(line, bytes):
                data =(line.decode())
                chain = data[12]
                begin_pdb = int(data[14:18])
                end_pdb = int(data[20:24])
                begin = int(data[55:60])
                end = int(data[62:67])
                list_attributes.append(begin_pdb)
                list_attributes.append(end_pdb)
                list_attributes.append(begin)
                list_attributes.append(end)
                dbref_dict[chain] = list_attributes
                
    final_dict = {}
    for k, v in dbref_dict.items():
        dict_new_id = {}
        if v[0] == v[2] and v[1] == v[3]:
            print('No difference in residue numbers in chain',k)   
        else:
            print('Difference in residue numbers in chain',k)
            sequence_length = v[3] - v[2] +1
            index = 0
            for i in range(sequence_length):
                dict_new_id[v[0]+index] = v[2]+index
                index +=1
        final_dict[k] = dict_new_id
    return(dbref_dict, final_dict)

def intraprotein_threshold(chain_entity_dict, entity):
    '''Calculates threshold for intraprotein contacts (within chains)
    
    Parameters
    ----------
        chain_entity_dict : dict obtained from entity_for_chain function
        entity : given an entity identifier (E1, E2, etc.) 
        
    Returns
    -------
        threshold value '''
    
    index = 0
    for i in chain_entity_dict.values():
        if i == entity:
            index +=1
    threshold = (index*50)/100
    return(int(threshold)) 

def entity_for_chain(PDB_ID):
    '''Gives us chain and entity information for a PDB structure
    
    Parameters
    ----------
        PDB_ID : input PDB_ID 
        
    Returns
    -------
        chain_entity_dict : dictionary with entity (values) that are identified for each chain (key) in the structure
        chainlist : list of chains present in the structure '''
    
    response1 = requests.get(f'https://data.rcsb.org/rest/v1/core/entry/{PDB_ID}').json()
    entity = response1['rcsb_entry_container_identifiers']['polymer_entity_ids']
    chain_entity_dict= {}
    chainlist = []

    for entity_id in entity:
        polymer_entity_url = "https://data.rcsb.org/rest/v1/core/polymer_entity/" + \
                            PDB_ID + "/" + entity_id
        response2 = requests.get(polymer_entity_url).json()
        chains = response2['entity_poly']['pdbx_strand_id']
        splitchains = chains.split(',')

        for c in splitchains:
            if isinstance(c, str):
                chain_entity_dict[c] = 'E'+ entity_id
                chainlist.append(c)

    return(chain_entity_dict, chainlist)